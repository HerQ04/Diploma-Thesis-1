{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from diffusers import UNet2DModel\n",
    "from diffusers import DDPMScheduler\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from diffusers import DDPMPipeline\n",
    "from dataclasses import dataclass\n",
    "from diffusers import DDPMPipeline\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    image_size = 32  # the generated image resolution\n",
    "    seed = 24\n",
    "    mixed_precision = \"fp16\"\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    gradient_accumulation_steps = 1\n",
    "    image_number= 64 #Number of test images\n",
    "    generated_images_output=\"\"\n",
    "    model_path=\"\"\n",
    "\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build U-net from saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet = UNet2DModel.from_pretrained(config.model_path)\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision=config.mixed_precision,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    log_with=\"tensorboard\",\n",
    "    project_dir=os.path.join(\"/artifacts/temp\", \"logs\"),\n",
    ")\n",
    "Unet = Unet.to(accelerator.device)\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "pipeline = DDPMPipeline(unet=accelerator.unwrap_model(Unet), scheduler=noise_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config, pipeline):\n",
    "    # Sample some images from random noise (this is the backward diffusion process).\n",
    "    # The default pipeline output type is `List[PIL.Image]`\n",
    "    images = pipeline(\n",
    "        batch_size=config.image_number,\n",
    "        generator=torch.manual_seed(config.seed),\n",
    "    ).images\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=evaluate(config, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create the output directory if itdoesn't exist\n",
    "if not os.path.exists(config.generated_images_output):\n",
    "    os.makedirs(config.generated_images_output)\n",
    "\n",
    "# Iterate over the images and save each one\n",
    "for i, img in enumerate(images):\n",
    "    # Construct the file path for each image\n",
    "    file_path = os.path.join(config.generated_images_output, f\"image_{i}.png\")\n",
    "    img.save(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) CUDA_VISIBLE_DEVICES=1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
